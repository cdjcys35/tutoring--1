---
title: "ADP4"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")
```

# Preparations (준비작업)

## Libraries

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(data.table)
library(tidyverse)

theme_set(theme_bw())
```

# 통계 검정

-   카이제곱 검정
-   일표본 t 검정
-   독립표본 t 검정
-   대응표본 t 검정
-   상관분석
-   one-way ANOVA
-   two-way ANOVA

**통계 검정 문제는 따로 안나오는걸로 파악했음**

# 범주형 자료분석 {.tabset .tabset-fade}

## 카이제곱 검정

두 범주형 변수 간의 연관성을 통계적으로 검정하는 방법

-   표본의 크기에 따라 방법에 차이가 있음

-   chisq.test(x, y = NULL, simulate.p.value = FALSE)

    -   x, y : 두 범주형 변수를 나타내는 벡터, 만약 x가 행렬 혹은 table 객체면 y는 무시

    -   simulate.p.value = F : 검정통계량의 근사분포로 카이제곱 분포를 이용하여 P-value 계산

**데이터 프레임 형태일 때**

```{r}
df_4 <- fread("https://goo.gl/j6lRXD")  #Reading CSV
df_4 <- df_4[,-"id"]
df_4
df_4_t <- table(df_4$treatment, df_4$improvement)
df_4_t
```

**표본의 크기가 클 때**

```{r}
chisq.test(df_4$treatment, df_4$improvement)
chisq.test(df_4_t)

```

**표본의 크기가 작을 때**

-   표본의 크기가 작을 때 simulation을 이용하는 방법과 피셔의 정확성 검정을 이용하는 방법 2가지가 있음

-   chisq.test()

    -   simulate.p.value = F : 검정통계량의 근사분포로 카이제곱 분포를 이용하여 P-value 계산

    -   simulate.p.value = T : 모의실험을 통하여 P-value 계산

-   fisher.test()

    -   simulate.p.value = T : 분할표가 2x2보다 큰 경우 P-value를 모의실험을 통해 계산할 것인지 여부

```{r}
chisq.test(df_4_t, simulate.p.value = T) 
fisher.test(df_4$treatment, df_4$improvement)
fisher.test(df_4_t)
```

**범주에 비해서 표본의 크기가 작을 때**

-   chisq.test에서 모의실험에 의한 p-value 계산
-   Fisher의 정확성 검정 적용
-   범주 축소

**Example**

| income | veryD | LittleD | ModerateS | VeryS |
|--------|-------|---------|-----------|-------|
| \<15K  | 1     | 3       | 10        | 6     |
| 15-25k | 2     | 3       | 10        | 7     |
| 25-40k | 1     | 6       | 14        | 12    |
| \>40K  | 0     | 1       | 9         | 11    |

```{r}
Job <- matrix(c(1,2,1,0, 3,3,6,1, 10,10,14,9, 6,7,12,11), 
              ncol = 4, 
              dimnames = list(income=c("<15k","15 25k","25 40k",">40k"),
              satisfaction=c("VeryD","LittleD", "ModerateS", "VeryS")))
Job.chi <- chisq.test(Job)
Job.chi$expected # 전체 칸 중 50%가 기대빈도수가 5 미만 
```

```{r}
chisq.test(Job, simulate.p.value = T)
fisher.test(Job)
```

-   범주 축소할 때 vcdExtra 패키지의 collapse.table 이용하면 편함

```{r}
# vcdExtra	0.7-1
library(vcdExtra)
Job
Job.r <- collapse.table(as.table(Job),
                        income=c("<25k","<25k",">25k",">25k"),
                        satisfaction=c("D","D","S","S"))
Job.r
chisq.test(Job.r)
```

**table을 만들라고 할 경우**

-   데이터 안주고 table 만들어서 분석하라고 할 수도 있음?(예상)

    | Group   | YES(heart attack) | NO(heart attack ) | Total |
    |---------|-------------------|-------------------|-------|
    | placebo | 189               | 10845             | 11034 |
    | aspirin | 104               | 10933             | 11037 |

```{r}
aspirin <- matrix(c(189,104,10845,10933), ncol =2,
                  dimnames=list(Group= c("Placebo","Aspirin"), 
                                HeartAttack = c("Yes","No")))
aspirin

chisq.test(aspirin)
```

## 범주형 자료 시각화

-   시험 때 시각화 문제는 랜덤이기 때문에 다방면으로 알고 있는게 좋음

```{r}
Arthritis %>% head()
arth_table <- table(Arthritis$Treatment, Arthritis$Improved)
```

**막대 그래프**

```{r}

# 원자료 이용 
Arthritis %>% 
  ggplot(aes(x = Treatment, fill = Improved)) + 
  geom_bar()

# table 이용 
arth_table %>%
  as.data.frame() %>%
  rename(Treatment = Var1, Improved = Var2) %>% 
  ggplot(aes(x = Treatment, y = Freq, fill = Improved)) + 
  geom_bar(stat = "identity")

# 원자료 이용 
Arthritis %>% 
  ggplot(aes(x = Treatment, fill = Improved)) + 
  geom_bar(position = "dodge")

Arthritis %>% 
  ggplot(aes(x = Treatment, fill = Improved)) + 
  geom_bar(position = "dodge2")

Arthritis %>% 
  ggplot(aes(x = Treatment, fill = Improved)) + 
  geom_bar(position = "fill")

```

**mosaic plot**

-   두 개 이상의 범주형 변수에 대해 시각화할 때 활용

```{r}
# vcd	1.4-8
library(vcd)
vcd::mosaic(Arthritis$Improved~Arthritis$Treatment, direction = "v")
vcd::mosaic(~Arthritis$Treatment + Arthritis$Improved, direction = "v")

```

# 집단 간 차이 검정 {.tabset .tabset-fade}

## 일표본 t 검정

모평균(theoretical mean)과 표본평균(observed mean)을 비교하기 위한 검정 방법

**Assumption**

-   정규성

**Example**

-   병을 채우는 기계가 병에 탄산음료 500ml의 부피로 채우도록 세팅되
-   실제 부피는 정규 분포를 따름
-   제조업자는 이 기계가 조금 500ml 보다는 부족하게 채운다고 믿음
-   20개의 병을 샘플로 하여 내부 액체의 부피를 측정함

```{r}
<<<<<<< HEAD
#df_1 <- fread("http://www.instantr.com/wp-content/uploads/2012/11/bottles.csv")
#write.csv(df_1, "data/df_1.csv")

df_1 <- fread("data/df_1.csv")

=======
df_1 <- fread("http://www.instantr.com/wp-content/uploads/2012/11/bottles.csv")
>>>>>>> 105625b6ece5919d09aa710164c008121ec30954
```

```{r}
boxplot(df_1$Volume)
```

**정규성 가정 확인**

```{r}
shapiro.test(df_1$Volume)
car::qqPlot(df_1$Volume)
```

**t test**

```{r}
t.test(df_1$Volume, mu = 500, alternative = "less")
```

**Non-normal 일 때**

**wilcoxon test**

```{r}
wilcox.test(df_1$Volume, mu = 500, alternative = "less")

```

## 독립표본 t 검정(Unpaired t test)

두 독립 그룹 간의 평균 차이에 대한 검정 방법

**Assumption**

-   정규성
-   등분산성

**Example**

```{r}
# Data in two numeric vectors
women_weight <- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)
men_weight <- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4) 
# Create a data frame
df_2 <- data.frame( 
                group = rep(c("Woman", "Man"), each = 9),
                weight = c(women_weight,  men_weight)
                )

df_2 <- df_2 %>% 
  mutate(group = as.factor(group))

df_2
```

```{r}
df_2 %>% 
  ggplot(aes(x = group, y = weight, fill = group)) + geom_boxplot()


```

**Check assumption**

**정규성 가정 확인**

```{r}
df_2_w <- df_2 %>% filter(group == "Woman") %>% select(weight)
df_2_m <- df_2 %>% filter(group == "Man") %>% select(weight)

shapiro.test(df_2_w$weight)
shapiro.test(df_2_m$weight)

```

**등분산성 가정 확인**

-   var.test의 귀무가설을 두 그룹의 분산비가 1임
-   귀무가설을 기각할 수 없으므로 가정 만족

```{r}
var.test(weight~group, data = df_2)
car::leveneTest(weight~group, data = df_2) 
```

**unpaired t-test**

```{r}
t.test(df_2_w, df_2_m, var.equal = T)
t.test(df_2$weight~df_2$group, var.equal = T)
```

**Equal variance 만족 안할 때**

**welch t-test**

```{r}
t.test(df_2_w, df_2_m, var.equal = F)
t.test(df_2$weight~df_2$group, var.equal = F)
```

## 대응표본 t 검정

동일한 대상에 대해서 전후 평균 차이를 비교하는 검정 방법

**Assumption**

-   정규성(전후 값의 차이에 대한 정규성)

**Example**

열마리 쥐에 대해서 약 투약 전후 체중에 대한 데이터가 존재함

```{r}
before <-c(200.1, 190.9, 192.7, 213, 241.4, 196.9, 172.2, 185.5, 205.2, 193.7)
# Weight of the mice after treatment
after <-c(392.9, 393.2, 345.1, 393, 434, 427.9, 422, 383.9, 392.3, 352.2)
# Create a data frame
df_3 <- data.frame( 
                group = rep(c("before", "after"), each = 10),
                weight = c(before,  after)
                )
df_3
```

```{r}
df_3 <- df_3 %>% 
  mutate(group = as.factor(group))


df_3 %>% 
  ggplot(aes(x = group, y = weight, fill = group)) +
  geom_boxplot() + 
  scale_x_discrete(limits = c("before", "after")) # 그래프에서 범주 순서 바꾸는 옵션 
```

**Check assumption**

```{r}
before <- df_3 %>% 
  filter(group == "before") %>% 
  select(weight)

after <- df_3 %>% 
  filter(group == "after") %>% 
  select(weight)

diff <- before$weight - after$weight

shapiro.test(diff)

```

**Paired t-test**

```{r}
t.test(before$weight, after$weight, paired = T)
t.test(df_3$weight~df_3$group, paired = T)
```

**Non-normal일 때**

```{r}
wilcox.test(df_3$weight~df_3$group, paired = T)

```

## t-test 정리

![<http://www.sthda.com/english/wiki/t-test-analysis-is-it-always-correct-to-compare-means>](images/t_test.PNG)

## 상관분석

**pearson correlation**

-   두 연속형 변수에 대한 상관관계를 분석
-   인과관계가 아닌 상관관계인 점 주의

**plot**

```{r}
plot(mtcars$mpg, mtcars$wt, xlab = "", ylab = "")
abline(lm(mtcars$wt~mtcars$mpg))

mtcars %>% 
  select(mpg, wt) %>% 
  ggplot(aes(x = wt, y = mpg)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = F) # se : 신뢰구간 

```

```{r}
cor(mtcars$mpg, mtcars$wt)
```

**Hypothesis** $$
\begin{align*}
H_0: \text{두 변수 간에 상관관계가 없다.} \\
H_1: \text{두 변수 간에 상관관계가 있다.}
\end{align*}
$$

**Assumption**

-   정규성 가정(두 확률변수 각각에 대해)

**Check assumption**

-   density plot
-   normal Q-Q plot
-   shapiro-wilk normality test

```{r}

# density plot 

plot(density(mtcars$mpg))
plot(density(mtcars$wt))


# QQ plot 
qqnorm(mtcars$mpg)
qqline(mtcars$mpg)

qqnorm(mtcars$wt)
qqline(mtcars$wt)

car::qqPlot(mtcars$mpg)

# shapiro test 

shapiro.test(mtcars$wt)
shapiro.test(mtcars$mpg)


```

**correlation test**

```{r}
cor.test(iris$Petal.Width, iris$Sepal.Length, method = "pearson")
```

**non-normal일 경우**

-   spearman
-   kendal's tau

```{r}
cor.test(iris$Petal.Width, iris$Sepal.Length, method = "kendall")
cor.test(iris$Petal.Width, iris$Sepal.Length, method = "spearman")

```

## one-way ANOVA

2개 이상 그룹의 평균 차이를 검정하는 방법

**Hypothesis**

$$
\begin{align*}
&H_0: \text{그룹 간 평균 차이가 없다.} \\
&H_1: \text{최소 하나 이상 그룹 간 평균 차이가 존재한다.}
\end{align*}
$$

**Asssumption**

1.  정규성
2.  등분산성(그룹 간)

**가정이 만족하는지 반드시 체크해야함**

**Data** 정유 회사 온도(factor)에 따라 휘발유 생산량에 차이가 있는지를 알아보려고 함

```{r}
y1 <- c(50.5, 52.1, 51.9, 52.4, 50.6, 51.4, 51.2, 52.2, 51.5, 50.8)  
y2 <- c(47.5, 47.7, 46.6, 47.1, 47.2, 47.8, 45.2, 47.4, 45.0, 47.9)  
y3 <- c(46.0, 47.1, 45.6, 47.1, 47.2, 46.4, 45.9, 47.1, 44.9, 46.2) 
y <- c(y1, y2, y3)  
n <- rep(10, 3) 
group <- rep(1:3, n) 
df <- data.frame(y, group) 
df %>% head()
```

<https://rfriend.tistory.com/131>

**변수 변환**

그룹 변수를 반드시 factor로 변환해줘야 함

```{r}
df <- df %>% 
  mutate(group = as.factor(group))
```

**시각화**

```{r}
boxplot(y~group, df, xlab = "temp factor", ylab = "")

df %>% 
  ggplot(aes(x = group, y = y, fill = group)) + geom_boxplot()
```

**One-way ANOVA**

```{r}
anova_result <- aov(y~group, data = df)
summary(anova_result)
```

**Check assumption**

-   정규성 가정은 너무 정규분포와 다르지 않아도 괜찮음
-   이봉 형태이거나 너무 치우쳐져 있으면 변환 or 비모수 검정 고려

```{r}
plot(density(anova_result$residuals))
plot(anova_result, 2)
```

```{r}
plot(anova_result, 1)

```

**정규성 위반 시**

**변환을 이용한 방법**

-   y에 대한 적절한 변환 진행 필요
-   log, sqrt, exp, x\^2 등이 있음
-   log 변환 시에 inf 값 주의, log(y+1)로 변환 필요
-   정규분포에 얼추 맞는 변환을 찾아야함(qqplot, density plot)

```{r, eval = F}
df2 <- df %>% 
  mutate(y = log(y))

anova_result2 <- aov(y~group, data = df2)
summary(anova_result2)
```

**비모수 검정**

-   변환해도 가정 만족 안할 시 고려할 필요가 있음
-   분포 가정이 없는 검정임

```{r, eval = F}
kruskal.test(y~group, df)
```

**이상치 있을 시**

```{r}
plot(anova_result, 4)
cooksd <- cooks.distance(anova_result)

plot(cooksd)
abline(h = 4*mean(cooksd, na.rm=T), col="red")
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red") 
```

```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])

head(df[influential, ]) 

```

```{r}
car::outlierTest(anova_result)

```

## two-way ANOVA

21회 기출 참고

# Clustering {.tabset .tabset-fade}

-   기출 확인 결과 clustering 모델을 적용하는 방법만 알고 있으면 됨 
-   SOM 같이 모르는 모델 나오면 못쓸 수도 있으므로 여러가지 모델을 정리해가는 것이 필요함 
-   factorextra 패키지가 시각화 및 기타 분석에 매우 유용함 

<<<<<<< HEAD



# Clustering
=======
```{r}
# factoextra	1.0.7
#devtools::install_version("factoextra", version = "1.0.7")
library(factoextra)
```
>>>>>>> 105625b6ece5919d09aa710164c008121ec30954

## k means

-    k-means는 거리 기반이므로 scaling 필수 
```{r}
df_6 <- scale(USArrests) # scale(x, center = TRUE, scale = TRUE)
```

**optimal cluster k**

-    factoextra 패키지를 이용하면 최적의 cluster 개수를 시각화해줌 
-    method는 여러 가지가 있음 
```{r}
fviz_nbclust(df_6, kmeans, method = "gap_stat")

```

**Compute k-means**

```{r}
set.seed(123)
km.res <- kmeans(df_6, 4, nstart = 25)
```

**Visualization**

```{r}
library("factoextra")
fviz_cluster(km.res, data = df_6,
             palette = c("#00AFBB","#2E9FDF", "#E7B800", "#FC4E07"),
             main = "Partitioning Clustering Plot"
             )

```

## hierarchical k-means

**optimal cluster k**

```{r}
fviz_nbclust(df_6, hkmeans, method = "gap_stat")

```

**Compute hk-means**

```{r}
res.hk <- hkmeans(df_6, 4)
```

**Visualization**

```{r}
fviz_dend(res.hk, rect = T) # rect = T : 정사각형 점선 추가 

```

<<<<<<< HEAD

## clustering 이후 classification 

=======
```{r}
fviz_cluster(res.hk, repel = TRUE) # repel = T : label 중첩 방지 
```

## PCA

-   factorextra 패키지가 가장 효율적
-   recipe를 이용할 수도 있지만 시각화 코드가 긴 단점이 있음
-   시각화까지 전부 해야되면 factorextra, 전처리만 해도 되면 recipes 쓰면 됨


**Example**
```{r}
df_5 <- decathlon2[1:23, 1:10]
df_5
```

-    그냥 prcomp 써도 상관없음 
```{r}
library(FactoMineR)
PCA(df_5, graph = T) # scale.unit = T default
```

**eigenvalue/variance 추출**

```{r}
res.pca <- PCA(df_5, graph = F) 
get_eig(res.pca)
```

**screeplot**

```{r}
fviz_screeplot(res.pca, addlabels = T) # add_labels = T : 퍼센트 표시 
```
**Bi plot**
```{r}
res.pca$var$coord %>% head()
fviz_pca_var(res.pca)
```

-   주성분 별로 계수의 효과를 파악하기 어렵기 때문에 plot을 그려서 확인 
-   화살표가 찍히는 좌표는 각 주성분에서 특정 변수의 가중치 값이 됨 
-   예를 들어 Pole.vault의 경우 PC1의 가중치는 -0.21, PC2의 가중치는 0.8이므로 해당 좌표에 점이 찍힘 
-   즉 주성분 축에 평행할수록 해당 변수는 주성분에 크게 기여했다고 볼 수 있음 
-   같은 각도로 뻗어나가는 경우 서로 비슷한 변수라고 볼 수 있음 

```{r}
fviz_pca_ind(res.pca, repel = T)

```

```{r}
res.pca$ind$coord %>% head()
fviz_pca_biplot(res.pca, repel = TRUE)

```
 



## hierarchical clustering

```{r}
fviz_nbclust(df_6, hcut, method = "gap_stat")
```

```{r}
res <- hcut(USArrests, k = 4, stand = T)
res
```

```{r}
fviz_dend(res, rect = TRUE)
```

## SOM

<https://rpubs.com/AlgoritmaAcademy/som>

```{r}
# kohonen	3.0.10
# devtools::install_version("kohonen", version = "3.0.10")
library(kohonen)

dat_7 <- fread("data/KAG.csv")

dat_7 %>% glimpse()
```
-   ad_id : an unique ID of each ad
-   xyz_campaign_id : an ID associated with each ad campaign of XYZ company
-   fb_campaign_id : an ID associated with how Facebook tracks each campaign
-   age : age of the person to whom the ad is shown
-   gender : gender of the person to whon thw ad si shown
-   interest : a code specifying the category to which the person's interest belongs (interests are as mentioned in the person's Facebook public profile)
-   Impressions : number of time the ad is shown
-   Clicks : number od click on for the ad
-   Spent : amount paid from xyz company to Facebook to shown the ad
-   Total_Conversion : total number of people who enquired about the product after seeing the ad
-   approved_Conversion : total number of people who bougth the product after seeing the ad

```{r}
dat_7 <- dat_7 %>% 
  mutate(ad_id = as.factor(ad_id),
         xyz_campaign_id = as.factor(xyz_campaign_id),
         fb_campaign_id = as.factor(fb_campaign_id)) 

```

**dummy coding**

-   범주형 변수에 대해 dummy coding 필요

```{r}
ads.s <- dat_7 %>% 
  mutate(genderM = ifelse(gender == "M", 1, 0),
         age2 = ifelse(age == "35-39", 1, 0),
         age3 = ifelse(age == "40-44", 1, 0),
         age4 = ifelse(age == "45-49", 1, 0)) %>% 
  select(-c(1,3:5))

```

```{r}
ads.train <- as.matrix(scale(ads.s[,-1]))
```

```{r}
# make a SOM grid
set.seed(100)
ads.grid <- somgrid(xdim = 10, ydim = 10, topo = "hexagonal")

# make a SOM model
set.seed(100)
ads.model <- som(ads.train, ads.grid, 
                  rlen = 500, 
                  radius = 2.5, # 뉴런의 반경 
                  keep.data = TRUE, # return original data  
                  dist.fcts = "euclidean")

```

```{r}
library(factoextra)
ads.model$codes[[1]] %>% dim()
set.seed(100)
fviz_nbclust(ads.model$codes[[1]], kmeans, method = "wss")
```

```{r}
set.seed(100)
clust <- kmeans(ads.model$codes[[1]], 6)
```

```{r}
# 각 class가 뉴런의 학습에 기여한 기여율 
plot(ads.model, type = "codes", bgcol = rainbow(9)[clust$cluster], main = "Cluster Map")
add.cluster.boundaries(ads.model, clust$cluster)

```

```{r}
ads.cluster <- data.frame(ads.s, cluster = clust$cluster[ads.model$unit.classif])
tail(ads.cluster, 5)
```

# Clustering and modeling tutorial {.tabset .tabset-fade}

<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>

UCI machine learning 데이터가 시험에 나오는 경우가 많은 것 같아서 kaggle tutorial 중에 pca 후 모델링 관련 괜찮은 데이터를 골랐습니다.

## 데이터 불러오기

```{r}
cancer <- fread("data/cancer.csv", fill = T) # fill = T : 행길이가 다를 경우 강제로 채워줌 

cancer <- cancer %>% 
  select(-c(id, V33)) %>% 
  janitor::clean_names()

cancer %>% glimpse()


```

## EDA

```{r}
library(corrplot)

cancer %>% 
  select_if(is.numeric) %>% 
  cor() %>% 
  corrplot()

```

```{r}
cancer$diagnosis <- factor(cancer$diagnosis, label = c("Benign", "Malignant"))
cancer %>% is.na() %>% colSums()
```

## PCA

-   PCA는 범주형 변수가 있으면 안되므로 numeric만 선택
-   변수 스케일에 대한 영향을 줄이기 위해 normalize 진행(center : 평균 빼기, scale : 분산으로 나누기)
-   cumulative proportion을 보면 PC1:PC5 정도 선택하면 전체 분산에 84% 설명

```{r}
cancer_pca <- cancer %>% 
  select_if(is.numeric)
pca_result <- prcomp(cancer_pca, scale = T, center = T)
summary(pca_result)
```

## Screeplot

-   fviz_eig로 screeplot을 그릴 수 있음

```{r}
fviz_eig(pca_result, addlabels = T)
```

## bi plot

-   fviz_pca_biplot()

    -   col.ind : 개별 관측치에 대해 특정 변수 기준으로 색을 다르게 부여

```{r}
fviz_pca_biplot(pca_result, col.ind = cancer$diagnosis, col = "black")
fviz_pca(pca_result)

```

## PCA한 결과로 dataframe을 만들 때

-   prcomp를 할당한 결과에서 x를 추출할 수 있음

```{r}
pca_columns <- pca_result$x %>% 
  as_tibble() %>% 
  select(PC1, PC2, PC3, PC4, PC5)

df_8 <- data.frame(diagnosis = cancer$diagnosis, pca_columns)
df_8
```

## recipes를 이용한 방법

-   단순히 PCA를 적용해서 모델링을 한다고 했을 때 recipes가 효율적

-   단점은 시각화 코드가 복잡해서 생략..

-   recipes도 stat 패키지의 prcomp 함수를 이용하므로 결과 동일

-   step_pca()

    -   threshold : 주성분을 총 변동의 몇 %를 설명할 정도로 선택할 것인지
    -   위의 예시를 보면 PC4 : 0.79, PC5 : 0.84인데 treshold를 0.80으로 잡으면 PC5까지 선택됨

```{r}
library(recipes)

cancer %>% 
  recipe(diagnosis~.) %>% 
  step_normalize(all_predictors()) %>% 
  step_pca(all_numeric(), threshold = 0.80) %>% 
  prep() %>% 
  juice()

```

```{r}
library(caret)
library(rsample)


splits <- initial_split(df_8, prop = 0.7, strata = diagnosis)
train <- training(splits)
test <- testing(splits)
```

```{r}
set.seed(123)
control <- trainControl(method='cv', 
                        number=5, 
                        classProbs = T, # target이 1 or 0이 아니라 yes or no 형태여야함.  
                        summaryFunction = twoClassSummary, # auc, sensitivity, specificity
                        savePredictions = T
                        )
tunegrid <- expand.grid(mtry = c(1:5))

library(tictoc)
tic()
rf_gridsearch <- train(diagnosis ~ .,             
                       data = train,               
                       method = 'rf',  
                       trControl = control,
                       tuneGrid = tunegrid,
                       metric = "ROC",
                       verbose = F) 
toc() 
rf_gridsearch

pred <- predict(rf_gridsearch, newdata = test, type = "raw")

cmatrix <- caret::confusionMatrix(pred, test$diagnosis) 
cmatrix

```
>>>>>>> 105625b6ece5919d09aa710164c008121ec30954
