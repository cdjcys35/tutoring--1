---
title: "ADP6"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---


```{r}
library(tidyverse)
library(data.table)
library(lubridate)
library(caret)
library(recipes)
library(rsample)
library(forecast)
```



# 고객 이탈 분류 문제 {.tabset .tabset-fade}

```{r}
list.files('data')
churn <- fread("data/BankChurners.csv")

```



## Data description

**original** 
**시험 때 나왔던 데이터**

| 성별 | 나이 | 카드등급 | 소득 | ...(15개 더) | y(고객이탈여부) |
|------|------|----------|------|--------------|-----------------|
|      |      |          |      |              |                 |
|      |      |          |      |              |                 |
|      |      |          |      |              |                 |

**시험과 비슷한 데이터**

```{r}
churn <- fread("data/BankChurners.csv")

churn <- churn %>% 
  select(-c(Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1, Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2, CLIENTNUM)) %>% 
  janitor::clean_names()

churn %>% 
  head() %>% 
  gt::gt()
```

-   Attrition_flag : target variable, 이탈 고객인지 유무
-   Gender: 성별
-   customer age : 고객의 나이
-   income category : 고객이 속한 소득 범주
-   card category : 고객이 갖고 있는 카드 범주
-   month inactive : 신용카드를 사용할 때 비활성 금액
-   credit limit : 카드 한도
-   total revolving balance : 다음달로 이월되는 미지급 금액
-   average utilization ratio : 사용 한도와 비교해서 사용 중인 금액의 비율
-   open to buy : 특정 고객에게 할당된 평균 사용 가능 금액

<https://www.kaggle.com/sakshigoyal7/credit-card-customers>

## EDA 및 전처리

```{r}
library(GGally)
churn %>% glimpse()

churn <- churn %>% 
  mutate_if(is.character, as.factor)
```

```{r}

churn %>%
  keep(is.numeric) %>%
  gather() %>%
  ggplot() +
  geom_histogram(mapping = aes(x=value,fill=key), color="black") +
  facet_wrap(~ key, scales = "free") +
  theme_minimal() +
  theme(legend.position = 'none')
  

churn %>%
  keep(is.factor) %>%
  gather() %>%
  ggplot() +
  geom_bar(mapping = aes(x=value,fill=key), color="black") +
  facet_wrap(~ key, scales = "free") +
  theme_minimal() +
  theme(legend.position = 'none')




churn %>% 
  select_if(is.numeric) %>% 
  ggpairs(columns = 1:7)

churn %>% 
  select_if(is.numeric) %>% 
  ggpairs(columns = 8:14)

churn %>% 
  ggplot(aes(x = income_category, fill = attrition_flag)) + 
  geom_bar(position = "fill")


library(ggmosaic)
churn %>% 
  ggplot() +
  geom_mosaic(aes(x = product(income_category, gender), fill = gender)) + 
  facet_grid(. ~attrition_flag)
  




```

**범주 불균형 처리**

```{r}
churn %>% is.na() %>% colSums()

rec <- churn %>% 
  recipe(attrition_flag~.) %>% 
  step_other(all_nominal(), threshold = 0.1) %>% 
  step_mutate(attrition_flag = factor(attrition_flag, labels = c("Attrited", "Existed")))
churn <- rec %>% prep() %>% juice()



churn %>%
  keep(is.factor) %>%
  gather() %>%
  ggplot() +
  geom_bar(mapping = aes(x=value,fill=key), color="black") +
  facet_wrap(~ key, scales = "free") +
  theme_minimal() +
  theme(legend.position = 'none')
```

## 분류모델 3개 적용 후 confusion matrix 출력

```{r}
splits <- initial_split(churn, prop = 0.7, strata = attrition_flag)

train <- training(splits)
test <- testing(splits)



set.seed(123)
control <- trainControl(method='cv', 
                        number=5, 
                        classProbs = T,   
                        summaryFunction = twoClassSummary, 
                        savePredictions = T
                        )
```

**Random forest**

```{r}
tunegrid <- expand.grid(mtry = c(1:5))

library(tictoc)
tic()
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
rf_gridsearch <- train(attrition_flag ~ .,             
                       data = train,               
                       method = 'rf',  
                       trControl = control,
                       tuneGrid = tunegrid,
                       metric = "ROC",
                       verbose = F) 
toc() # 343.98
stopCluster(cl)
rf_gridsearch

plot(varImp(rf_gridsearch, scale = F))

pred <- predict(rf_gridsearch, newdata = test, type = "raw")

cmatrix <- caret::confusionMatrix(pred, test$attrition_flag) 
cmatrix

cmatrix$byClass


```

**svm**

```{r}
splits <- initial_split(churn, prop = 0.7, strata = attrition_flag)

train <- training(splits)
test <- testing(splits)


set.seed(123)
control <- trainControl(method='cv', 
                        number=5, 
                        classProbs = T,   
                        summaryFunction = twoClassSummary, 
                        savePredictions = T
                        )

library(tictoc)
tic()
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
svm_gridsearch <- train(attrition_flag ~ .,             
                       data = train,               
                       method = 'svmPoly',  
                       trControl = control,
                       tuneLength = 3, 
                       metric = "ROC",
                       verbose = F) 
toc() # 343.98
stopCluster(cl)
svm_gridsearch

train %>% str()

# DALEX	2.0.1
library(DALEX)
ex <- DALEX::explain(model = svm_gridsearch, 
               data = train[,-20], 
               y = train$attrition_flag)

vip <- model_parts(explainer = ex, B = 50)
plot(vip)

pred <- predict(svm_gridsearch, newdata = test, type = "raw")

cmatrix <- caret::confusionMatrix(pred, test$attrition_flag) 
cmatrix

cmatrix$byClass


```

**penalized logistic reg**

```{r}

library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
logit_gridsearch <- train(attrition_flag ~ .,             
                       data = train,               
                       method = 'glmnet',  
                       trControl = control,
                       tuneLength = 20, 
                       metric = "ROC") 

logit_gridsearch
stopCluster(cl)
plot(varImp(logit_gridsearch, scale = F))

pred <- predict(logit_gridsearch, newdata = test, type = "raw")

cmatrix <- caret::confusionMatrix(pred, test$attrition_flag) 
cmatrix

cmatrix$byClass
```

**custom**

```{r}
library(gt)
churn %>% 
  head() %>% 
  gt()


```



## EDA 및 전처리 
**logistic reg**

```{r}
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
logit2_gridsearch <- train(attrition_flag ~ .,             
                       data = train,               
                       method = 'glm',  
                       trControl = control,
                       tuneLength = 20, 
                       metric = "ROC") 
stopCluster(cl)
logit2_gridsearch

plot(varImp(logit_gridsearch, scale = F))

pred <- predict(logit2_gridsearch, newdata = test, type = "raw")

cmatrix <- caret::confusionMatrix(pred, test$attrition_flag) 
cmatrix

cmatrix$byClass


```

## 3개 모델 앙상블 모형 생성 후 예측값 저장

**Averaging**

-   classification일 때 예측값을 평균내는 것은 부적절
-   따라서 예측값 대신 예측 확률값을 평균 내서 최종 앙상블 결과로 산출

```{r}
result <- data.frame(rf = predict(rf_gridsearch, newdata = test, type = "prob"), 
           svm = predict(svm_gridsearch, newdata = test, type = "prob"), 
           logit = predict(logit2_gridsearch, newdata = test, type = "prob"))

result$average <- (result$rf.Existed + result$svm.Existed + result$logit.Existed)/3

result

result$average_c <- as.factor(ifelse(result$average>0.5, "E", "A"))

result %>% head()
```

**Voting**

-   다수결 투표에 의해 최종 예측값을 산출하는 방식
-   모형이 3개 이므로 2개 이상 예측 결과가 같은 경우 최종 예측값으로 산출

```{r}
result2 <- data.frame(rf = predict(rf_gridsearch, newdata = test, type = "raw"), 
           svm = predict(svm_gridsearch, newdata = test, type = "raw"), 
           logit = predict(logit2_gridsearch, newdata = test, type = "raw"))

result2$voting <- as.factor(ifelse(result2$rf == "Existed" & result2$svm == "Existed", "E",
                                   ifelse(result2$rf == "Existed" & result2$logit == "Existed", "E", 
                                          ifelse(result2$svm == "Existed" & result2$logit == "Existed", "E", "A"))))

result2 %>% head()
```

**weighted average**

-   모델 별로 예측 정확도가 다르기 때문에 예측 정확도가 높은 모델에 더 큰 가중치를 부여한 후 평균을 내는 방식
-   예측 평가 지표는 임의로 선택하면 됨(모든 모델에 공통으로)

```{r}
# rf : 0.9868
# svm : 0.9306
# logit : 0.9042

rf_w <- 0.9868/(0.9868 + 0.9306 + 0.9042)
svm_w <- 0.9306/(0.9868 + 0.9306 + 0.9042)
logit_w <- 0.9042/(0.9868 + 0.9306 + 0.9042)



result3 <- data.frame(rf = predict(rf_gridsearch, newdata = test, type = "prob"), 
           svm = predict(svm_gridsearch, newdata = test, type = "prob"), 
           logit = predict(logit2_gridsearch, newdata = test, type = "prob"))

result3$average <- (result$rf.Existed*rf_w) + (result$svm.Existed*svm_w) + (result$logit.Existed*logit_w)

result3

result3$weight_average <- as.factor(ifelse(result3$average>0.5, "E", "A"))

result3 %>% head()
```

## 예측 결과 csv 제출

-   raw or prob 구분해서 제출

# 시계열 데이터 분석 {.tabset .tabset-fade}

## Data description

-   날짜 및 주가 수익률 데이터로 time series 변환 전 데이터 제공

-   주가 데이터는 계절 추세가 있는 데이터를 못찾아서 river flow에 대한 데이터로 대체함

## 데이터 로드, 정상성/이분산성 검증

```{r}
flow <- ts(scan('https://online.stat.psu.edu/stat510/sites/stat510/files/data/coloradoflow.dat'),start = c("1960"), frequency = 12)
plot(flow)

flow %>% length()
```

```{r}
ggtsdisplay(flow)
```

-   계절 추세가 존재하는 것으로 보임
-   일반 추세도 존재? 확인 필요

## 정상성 파악 근거에 따른 고정(stationary)시계열 여부 파악

-   test 결과 일반 차분, 계절 차분 추천

```{r}
ndiffs(flow)
nsdiffs(flow)
```

**계절 차분**

```{r}
flow_sdif <- diff(flow, 12)
ggtsdisplay(flow_sdif, lag.max = 48)
```

**일반 차분**

```{r}
flow_dif <- diff(flow, 1)
ggtsdisplay(flow_dif, lag.max = 48)

```

```{r}
flow_dif_s <- diff(flow_dif, lag = 12)
ggtsdisplay(flow_dif_s, lag.max = 48)

```

-   최종적으로 계절 차분만 해도 추세가 무작위 변동으로 바뀌었기 때문에 정상성 만족
-   굳이 일반 차분까지 할 필요 없을 듯?

## SARIMA 분석 및 최적 모형 파라미터 선택

```{r}
flow_sdif <- diff(flow, 12)
ggtsdisplay(flow_sdif, lag.max = 48)
```

**후보모형** - ARIMA(1, 0, 0)(0, 1, 1)\_12 - ARIMA(1, 0, 0)(0, 1, 2)\_12

**ARIMA(1, 0, 0)(0, 1, 1)\_12**

-   모든 모수 유의
-   모형 가정 만족 x

```{r}
fit1 <- Arima(flow_sdif, order=c(1,0,0), seasonal=list(order=c(0,1,1),period=12))
confint(fit1) # 모든 모수 유의 
checkresiduals(fit1) # 모형 가정 만족 x 

```

**ARIMA(1, 0, 0)(0, 1, 2)\_12**

-   모든 모수 유의
-   모형 가정 만족

```{r}
fit2 <- Arima(flow_sdif, order=c(1,0,0), seasonal=list(order=c(0,1,2),period=12))
confint(fit2) # 모든 모수 유의 
checkresiduals(fit2) # 모형 가정 만족  

```

-   추가된 모수 비유의
-   잠정 모형으로 선택

```{r}

confint(Arima(flow_sdif, order=c(2,0,0), seasonal=list(order=c(0,1,2),period=12)))
confint(Arima(flow_sdif, order=c(1,0,1), seasonal=list(order=c(0,1,2),period=12)))

```

**auto.arima**

-   모든 모수 유의
-   가정 만족 x

```{r}
fit3 <- auto.arima(flow, d = 0, D = 1)
confint(fit3)
checkresiduals(fit3)
```

-   추가된 모수 비유의
-   ARIMA(1, 0, 0)(1, 1, 2)\_12 잠정 모형으로 선택

```{r}
confint(Arima(flow_sdif, order=c(2,0,0), seasonal=list(order=c(1,1,2),period=12)))
confint(Arima(flow_sdif, order=c(1,0,1), seasonal=list(order=c(1,1,2),period=12)))

```

-   aic, bic 비교 결과 ARIMA(1, 0, 0)(0, 1, 2)\_12를 최종 모형으로 선택

```{r}
fit2 <- Arima(flow_sdif, order=c(1,0,0), seasonal=list(order=c(0,1,2),period=12))
fit3 <- Arima(flow_sdif, order=c(1,0,0), seasonal=list(order=c(1,1,2),period=12))

c(fit2$aic, fit3$aic)
c(fit2$bic, fit3$bic)


```

## 잔차 그래프 출력

```{r}
checkresiduals(fit2)

```

## 분석 결과 PDF 제출

```{r}
plot(forecast(fit2))

```
