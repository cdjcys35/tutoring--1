---
title: "ADP 21회차 기출"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")
```

# Preparations (준비작업) {.tabset .tabset-fade}

## Libraries

ADP 시험 때 쓸 수 있는 패키지는 현재 기준 최신 버전이 아니라 약 2020년 초 버전입니다. 따라서 시험장에서 제공하는 패키지 버전을 기준으로 설치를 하고 실습을 진행해야합니다. 홈페이지에 사용할 수 있는 패키지와 version이 나와있기 때문에 참고하시면 됩니다.

<https://www.dataq.or.kr/www/board/notice/list.do>

**2 page 제 21회 데이터분석 전문가(ADP) 실기시험 응시안내**

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}

# 패키지 구버전 설치방법 

# devtools::install_version("recipes", version = "0.1.15")
# devtools::install_version("data.table", version = "1.13.4")
# devtools::install_version("caret", version = "6.0-86")
# devtools::install_version("GGally", version = "2.0.0")
# devtools::install_version("tidyverse", version = "1.3.0")
# devtools::install_version("janitor", version = "2.0.1")
# devtools::install_version("rsample", version = "0.0.8")
# devtools::install_version("DescTools", version = "0.99.39")
# devtools::install_version("car", version = "3.0-10")
# enter를 누르면 skip됩니다. 


library(data.table)
library(tidyverse)
library(caret)
library(recipes)
library(GGally)
library(janitor)

theme_set(theme_bw())
```

## Data load {.tabset .tabset-fade}

```{r}
file_path <- "./data/"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
dat <- fread(file.path(file_path, "student-mat.csv"))
```

```{r}
dat %>% names()
dat %>% dim()
dat <- dat %>% 
    dplyr::select(school, sex, paid, famrel, freetime, goout, Dalc, Walc, health, absences, G3) %>% 
    filter(G3%in%c(0, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18)) %>% 
    mutate(G3 = replace(G3, G3 == 6, 1), 
           G3 = replace(G3, G3 == 8, 2),
           G3 = replace(G3, G3 == 9, 3),
           G3 = replace(G3, G3 == 10, 4),
           G3 = replace(G3, G3 == 11, 5),
           G3 = replace(G3, G3 == 12, 6),
           G3 = replace(G3, G3 == 13, 7),
           G3 = replace(G3, G3 == 14, 8),
           G3 = replace(G3, G3 == 15, 9),
           G3 = replace(G3, G3 == 16, 10),
           G3 = replace(G3, G3 == 18, 11),
           ) %>% 
    rename(grade = G3) -> dat

dat %>% dim()

index <- sample.int(n = 366, size = 10)

dat[index, 'goout'] <- NA

# dat %>% names()
# dat %>% 
#   recipe(grade~.) %>% 
#   step_mutate(grade = as.factor(grade)) %>% 
#   recipes::step_upsample(grade, over_ratio = 1)%>% 
#   prep() %>% 
#   juice() -> dat
#   
# dat <- dat %>% 
#   mutate(grade = as.integer(grade)) 

```

# Data description

-   school - student's school (binary: "GP" - Gabriel Pereira or "MS" - Mousinho da Silveira)

-   sex - student's sex (binary: "F" - female or "M" - male)

-   paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)

-   famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)

-   freetime - free time after school (numeric: from 1 - very low to 5 - very high)

-   goout - going out with friends (numeric: from 1 - very low to 5 - very high)

-   Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)

-   Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)

-   health - current health status (numeric: from 1 - very bad to 5 - very good)

-   absences - number of school absences (numeric: from 0 to 93)

-   G3 - final grade (numeric: from 0 to 20, output target)

```{r}
dat %>% head()
dat %>% glimpse()
dat %>% str()

dat <- dat %>% 
    janitor::clean_names() # 한글일 때는 주의 필요 
```

# EDA(탐색적 자료분석) {.tabset .tabset-fade}

## 변수 속성 변환

-   변수별 그래프를 그리기 전에 변수별 속성을 확인하고 바꿔줘야함

    -   mutate : 지정된 변수 하나에 대해 조작하는 함수

    -   mutate_if : 지정된 조건에 해당하는 변수만 조작하는 함수

    -   mutate_at : 지정된 변수 전체에 대해 조작하는 함수

```{r}
# mutate_at 
dat %>% 
    mutate_at(vars(starts_with('f')), log)

standardize <- function(x, na.rm = T){
    (x - mean(x, na.rm = T))/sd(x, na.rm = T)
}
dat %>% 
    mutate_at(vars(starts_with('f')), standardize)

dat %>% 
    mutate_at(vars('freetime', 'goout'), standardize)

dat %>% 
    mutate_at(c('freetime', 'goout'), standardize)

# mutat_if 
dat %>% 
    mutate_if(is.integer, standardize)

dat %>% 
    mutate_if(is.integer, as.factor)


```

```{r}
dat <- dat %>% 
    mutate_if(is.character, as.factor) %>% 
    mutate(grade = as.integer(grade))
```

## 데이터 요약통계량

-   결측치 및 이상치 확인

-   변수별 요약 통계량 확인

```{r}
dat %>% summary()
```

## visualization

-   반응변수 vs 설명변수 상관계수 확인

-   설명변수 vs 설명변수 상관계수 확인

-   변수별 분포 확인(연속형 변수의 분포의 치우침, 범주형 변수의 class 불균형 확인)

-   범주형 설명변수와 반응변수 boxplot 그리기

<!-- -->

-   Package : **GGally**
-   문제 : 시각화 및 EDA

**여기서 주의해야할 점은 시각화에 많은 시간을 소요하면 안됩니다. 시각화 배점은 5점 정도이고, 문제에서 요구하는 것이 모호하기 때문에 필요 이상으로 쓰지 않아도 점수가 깍이지 않습니다. 따라서 형식적인 시각화 및 짧은 해석을 하고 넘어갑니다.**

```{r}
dat %>% 
    select_if(is.factor) %>% # factor 변수 선택  
    ggpairs()

dat %>% 
    select_if(is.integer) %>% 
    ggpairs()


dat %>% 
    ggplot(aes(x = school, y = grade)) + geom_boxplot()

dat %>% 
    ggplot(aes(x = sex, y = grade)) + geom_boxplot()

dat %>% 
    ggplot(aes(x = paid, y = grade)) + geom_boxplot()
```

# Data preprocessing(데이터 전처리)

# Recipes 패키지 소개

Recipes는 데이터 전처리에 필요한 여러가지 유용한 함수가 집약된 패키지입니다. ADP 시험에서 Recipes가 유용한 이유는 결측치 대치, 변수 속성 변경, encoding, upsampling, pca 등 데이터 전처리에 관한 거의 모든 것을 Recipes 패키지 하나로 처리할 수 있기 때문에 시간을 절약할 수 있고, 에러가 날 확률이 적습니다.

**Recipes** 패키지는 원래 tidymodels(파이썬의 sklearn 같은)에서 이용하는 패키지로 모델을 구축하기 이전에 데이터 전처리가 필요할 경우 이용하는 패키지입니다. 따라서 원래는 tidymodels의 고유한 workflow 안에 **Recipes** 가 포함되어 있으며, tidymodels의 고유한 workflow에 맞게 패키지가 설계되어있습니다. ADP 시험에서는 tidymodels를 이용할 수 없고 **Recipes** 만 이용하기 때문에 기존의 tidymodels workflow를 살짝 수정해서 이용합니다.

**Recipes** 함수를 이용하기 위해서는 **Recipes** 패키지만의 고유한 workflow를 이해해야 합니다. workflow는 총 3단계로 구성되어 있습니다.

1.  formula 정의 및 feature engineering

    -   recipes(formula) : 모델을 구축하기 이전에 반응변수와 설명변수를 formula로 지정

    -   step_function : recipe 내에 구축된 데이터 전처리 함수

Recipe를 지정한다고 해서 데이터가 바로 바뀌지 않습니다. Recipes를 쉽게 생각하면 파이썬의 class 처럼 실행을 한다고 바로 바뀌는 것이 아니라 어떻게 전처리를 할 것인지 지정하는 단계라고 이해하면 됩니다.

**Example**

```{r}
dat %>% 
  recipe(grade~.) %>% 
  step_meanimpute(goout)

```

2.  preparation

    -   prep() : recipes에서 지정한 전처리 함수를 변환하기 이전에 준비하는 단계

preperation도 Recipes와 마찬가지로 prep()을 한다고 데이터가 바뀌지 않습니다. prep()는 recipe에서 지정한 전처리 recipes를 다른 데이터셋에 적용할 수 있도록 필요한 파라미터를 추정하는 단계입니다. 별다른 의미가 있는 것이 아니라 마지막 juice 단계 이전에 무조건 사용해야하는 함수라고 이해하시면 됩니다.

**Example**

```{r}
dat %>% 
  recipe(grade~.) %>% 
  step_meanimpute(goout) %>% 
  prep()

```

3.  juice

    -   juice() : recipes에서 정의한 데이터 전처리 함수를 적용해서 데이터를 추출하는 단계

juice는 Recipe, prep 단계를 거치면서 정의된 모듈에서 데이터를 추출하는 함수라고 이해하시면 됩니다.

정리하면 요리를 만들 때와 같이 Recipe를 준비하고, 요리에 필요한 재료를 prep()하고, 음식을 만드는 juice() 단계라고 이해하시면 됩니다.

```{r}
dat %>% 
  recipe(grade~.) %>% 
  step_meanimpute(goout) %>% 
  prep() %>% 
  juice()

```

**Recipes**를 이용해서 결측치를 대치하는 방법에 대해 알아보겠습니다.

# 결측치 처리 {.tabset .tabset-fade}

-   통계량을 이용한 결측치 처리 방법

    -   평균 대치법

    -   중앙값 대치법

    -   최빈값 대치법

-   모형을 이용한 결측치 처리 방법

    -   회귀분석을 이용한 대치법

    -   의사결정나무를 이용한 대치법

    -   KNN을 이용한 대치법

-   **Package : Recipes**

-   문제 : 결측치 식별, 결측치 대치 방법 2가지, 선택 이유 설명

## 결측치 확인

```{r}
# r base 
dat %>% is.na() %>% colSums()

# dplyr
dat %>% 
    summarise_all(funs(sum(is.na(.))))


```

## 평균 대치법

변수의 분포가 대칭 형태일 때 사용

```{r}
library(recipes)

dat %>% 
    recipe(grade~.) %>% 
    step_meanimpute(goout) %>% 
    prep() %>% 
    juice() %>%
    
    is.na() %>% 
    colSums()

# dat$goout[is.na(dat$goout)] <- mean(dat$goout, na.rm = T)
```

## 중앙값 대치법

변수의 분포가 치우쳐져 있을 때 혹은 이상치가 존재하는 경우 사용

```{r}
#devtools::install_version("recipes", version = "0.1.15")
library(recipes)

dat %>% 
    recipe(grade~.) %>% 
    step_medianimpute(goout) %>% 
    prep() %>% 
    juice() %>% 
    is.na() %>% 
    colSums()

# dat$goout[is.na(dat$goout)] <- median(dat$goout, na.rm = T)
```

## 최빈값 대치법

변수가 character, factor 일 때 사용

```{r}
library(recipes)
# step_modeimpute의 경우 변수의 속성이 character or factor가 아니면 오류가 발생하므로 각주 처리함
# dat %>% 
#     recipe(grade~.) %>% 
#     step_modeimpute(goout) %>% 
#     prep() %>% 
#     juice() %>% 
#     is.na() %>% 
#     colSums()

# 변수 속성 상관없이 최빈값으로 바꿔줘야할 때 
# dat$goout[is.na(dat$goout)] <- mode(dat$goout, na.rm = T)
```

## 회귀분석을 이용한 대치법

```{r}
dat %>% 
    recipe(grade~.) %>% 
    step_impute_linear(goout, impute_with = imp_vars(paid, sex, freetime)) %>% 
    prep() %>% 
    juice() %>% 
    is.na() %>% 
    colSums()

dat %>% 
    recipe(grade~.) %>% 
    step_impute_linear(goout, impute_with = imp_vars(all_predictors())) %>% 
    prep() %>% 
    juice() %>% 
    is.na() %>% 
    colSums()

```

## bagged tree model을 이용한 대치법

```{r}
dat %>% 
    recipe(grade~.) %>% 
    step_bagimpute(goout, impute_with = imp_vars(all_predictors())) %>% 
    prep() %>% 
    juice() %>% 
    is.na() %>% 
    colSums()
```

## KNN을 이용한 대치법

**권장하진 않는 이유**

-   계산량이 많고, 이상치에 민감함

-   변수 scale에 민감하며, 고차원 데이터의 경우 부정확할 수 있음

```{r}
dat %>% 
    recipe(grade~.) %>% 
    step_knnimpute(goout, impute_with = imp_vars(all_predictors())) %>%
    prep() %>% 
    juice() %>% 
    is.na() %>% 
    colSums()
```

## 최종 대치방법

-   모형을 이용한 결측치 대치법은 어떤 방법을 써도 무방함

-   시험에서는 regression을 이용한 대치 방법, bagged tree model의 tree 수를 적당히 지정하고 빠르게 결측치를 대치할 것을 권장함

```{r}
dat1 <- dat %>% 
    recipe(grade~.) %>% 
    step_bagimpute(goout, impute_with = imp_vars(all_predictors())) %>% 
    prep() %>% 
    juice()

dat1 %>% is.na() %>% colSums()
```

# Encoding 방법 {.tabset .tabset-fade}

-   Label encoding

-   one-hot encoding

-   package : **Recipes**

-   문제 : 범주형 변수 인코딩이 필요한 경우 식별, 변환 적용, 특정 인코딩 방법 선택 이유

## Label encoding

-   알파벳 순으로 번호를 매기기 때문에 범주형 변수 코딩에 대한 수치 정보가 반영되는 문제가 있음

-   순서형 변수일 경우 사용

```{r}
dat1 %>% 
  recipe(grade~.) %>% 
  step_dummy(all_nominal()) %>% 
  prep() %>% 
  juice()
```

## one-hot encoding

-   Label encoding의 문제점인 수치 정보가 반영되는 문제를 해결 가능

-   범주형 변수 간의 다중공선성 문제가 있을 수 있음(회귀분석에서 문제가 되지만 glm 패키지에서는 factor로 처리할 경우 levels 중에 하나를 제외하기 때문에 one-hot encoding 필요 없음)

-   차원이 늘어남에 따라 계산량이 늘어나는 문제가 있음

-   순서형 변수가 아닐 때 모두 사용 가능

```{r}
dat1 <- dat1 %>% 
  recipe(grade~.) %>% 
  step_dummy(all_nominal(), one_hot = T) %>% 
  prep() %>% 
  juice()
```

# Data split(데이터 분할) {.tabset .tabset-fade}

-   Simple random sampling

-   strata sampling

-   package : **rsample(권장), caret**

-   문제 : 데이터셋 분할 방법 2가지 제시, 적절한 데이터 분할 방법 적용, 선택 이유 설명

## simple random sampling

-   데이터를 무작위로 특정 비율로 분할

-   범주형 변수의 class가 불균형할 때 랜덤 샘플링을 할 경우 train or test 데이터가 전체 데이터를 대표하지 못함

-   연속형 변수의 경우 분포가 치우쳐져 있을 때 같은 문제가 발생함

```{r}
# caret 패키지 이용 
library(caret)
set.seed(1234)
train_index <- createDataPartition(dat$grade, p = 0.7, list = F) 
# list = FALSE avoids returning the data as a list

train <- dat[train_index, ]
test <- dat[-train_index, ]

# rsample 패키지 이용 
library(rsample)
splits <- initial_split(dat, prop = 0.7)
train <- training(splits)
test <- testing(splits)
```

## strata sampling

-   class 불균형 문제에 대한 해결 방안으로 class의 빈도를 고려해서 샘플링을 진행함

-   연속형 변수의 경우, quantile을 기준으로 bin을 나눠서 샘플링을 진행함

![연속형 변수 층화 샘플링 예시](https://www.tmwr.org/figures/ames-sale-price-1.svg)

```{r}
# caret 패키지 이용 
library(caret)
set.seed(1234)
train_index <- createDataPartition(dat$sex, p = 0.7, list = F) 
# 층화를 위해서 nominal variable을 파라미터로 사용 
# list = FALSE avoids returning the data as a list

train <- dat[train_index, ]
test <- dat[-train_index, ]



# rsample 패키지 이용 
library(rsample)
splits <- initial_split(dat1, prop = 0.7, strata = grade)
train <- training(splits)
test <- testing(splits)

```

# Modeling {.tabset .tabset-fade}

-   SVM

-   XGBOOST

-   Random forest

-   package : **caret**

-   문제 : 3개 알고리즘의 공통점을 쓰고, 예측 분석에 적합한 알고리즘인지 설명. 현업에서 쓸 때 고려해야할 점 작성

# Caret package

caret은 머신러닝 모델링을 위한 패키지입니다. caret은 거의 대부분의 머신러닝 모델을 지원합니다. ADP 시험에서 caret을 이용하는 이유는 여러가지 모델을 caret workflow를 이용해서 한번에 처리할 수 있기 때문에 시간을 절약할 수 있습니다. 개별 패키지를 caret으로 불러와서 사용하는 것이기 때문에 개별 패키지를 이용한 결과와 차이가 없습니다.

## Caret workflow

caret의 workflow는 모델을 적합하는 순서와 동일합니다.

1.  validation set 생성
2.  tuning parameter 지정
3.  train 진행

**caret을 이용해서 학습할 때 주의점**

1.  validation set 구성 시 적당한 fold 값 지정(3\~5)
2.  튜닝해야할 하이퍼파라미터 지정 시 너무 많은 파라미터를 넣지 말 것
3.  튜닝해야할 하이퍼 파라미터가 애매하면 **tuneGrid** 대신 **tuneLength** 사용

## Random forest

```{r}
library(caret)

set.seed(123)
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3, 
                        search='grid')

tunegrid <- expand.grid(mtry = c(1:5))

rf_gridsearch <- train(grade ~ .,             
                       data = train,               
                       method = 'rf',
                       trControl = control, 
                       metric = 'RMSE',
                       tuneGrid = tunegrid, 
                       verbose = F) 

plot(varImp(rf_gridsearch, scale = F))


pred <- predict(rf_gridsearch, newdata = test)
print(RMSE(pred, test$grade))


```

```{r}
pred %>% head() # integer가 아님
pred %>% round() %>% head()

pred_r <- pred %>% round() 
print(RMSE(pred_r, test$grade))

```

## XGBOOST

```{r, message=FALSE, warning=FALSE}
library(caret)
set.seed(123)
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3, 
                        search='grid')

modelLookup('xgbTree') # 학습해야할 하이퍼 파라미터 명칭 확인 

# rf_gridsearch <- train(grade ~ .,             
#                        data = train,               
#                        method = 'xgbTree',         
#                        metric = 'RMSE',
#                        tuneLength = 10)
# expand.grid를 사용하기 위해서는 개별 파라미터를 모두 지정해줘야함 
tunegrid <- expand.grid(
  nrounds = seq(from = 200, to = 1000, by = 50),
  eta = c(0.025, 0.05, 0.1, 0.3),
  max_depth = c(2, 3, 4, 5, 6),
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)
library(tictoc)
tic()
xgb_gridsearch <- train(grade ~ .,             
                       data = train,               
                       method = 'xgbTree',         
                       metric = 'RMSE',
                       trControl = control,
                       tuneGrid = tunegrid, 
                       verbose = F)
toc() # 311.22 sec 
plot(varImp(xgb_gridsearch, scale = F))

pred <- predict(xgb_gridsearch, newdata = test)
print(RMSE(pred, test$grade))

pred_r <- pred %>% round() 
print(RMSE(pred_r, test$grade))

```

## SVM

```{r}
modelLookup('svmPoly')

set.seed(123)
control <- trainControl(method='repeatedcv', 
                        number=5, 
                        repeats=3, 
                        search='grid')


svm_gridsearch <- train(grade ~ .,             
                       data = train,               
                       method = 'svmPoly',         
                       metric = 'RMSE',
                       trControl = control, 
                       tuneLength = 3) # 전체 hyperparameter에 대한 조합의 수 

# plot(varImp(svm_gridsearch)) : 분류문제일 때만 그래프 그릴 수 있음 

pred <- predict(svm_gridsearch, newdata = test)
print(RMSE(pred, test$grade))

pred_r <- pred %>% round() 
print(RMSE(pred_r, test$grade))

```

# Modeling  {.tabset .tabset-fade}

-   Multiple regression

-   Ridge regression

-   LASSO regression

-   ELASTIC NET regression

-   문제

    -   데이터를 8:2로 분할하기

    -   Multiple regression 적합 후 R2, MSE 값 산출

    -   Ridge regression 적합 후 R2, MSE 값 산출

        -   alpha 값을 0\~1까지 0.1 단위로 모두 탐색 후 최적의 파라미터 선택

    -   LASSO regression 적합 후 R2, MSE 값 산출

        -   alpha 값을 0\~1까지 0.1 단위로 모두 탐색 후 최적의 파라미터 선택

## Bias, variance의 의미

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%253A%252F%252Fblog.kakaocdn.net%252Fdn%252FCjfRn%252FbtqPJNiMUQp%252FlcA2t6vgEN7rsNrrGdKjpK%252Fimg.jpg)

$$
E[Y-\hat{Y}|X] = \sigma^2 + Bias^2 + Variance 
$$

편향과 분산 두가지 모두 낮은 모형이 최적 모형임. 그렇다면 편향과 분산을 동시에 낮출 수 있을까? bias-variance는 trade off 관계이므로 불가능함.

![](https://www.endtoend.ai/assets/blog/misc/bias-variance-tradeoff-in-reinforcement-learning/underfit_right_overfit.png)

![](https://i.stack.imgur.com/eVFct.png)

Model complexity(polynomial의 차수)가 복잡해질수록 훈련 데이터에 대한 total error는 지속적으로 감소하지만 test data 관점에서는 일정 부분 감소하다가 빠르게 증가함. bias-variance 관점에서 보면 두가지를 모두 낮추는 것은 불가능하므로 타협점을 찾는 것이 필요함.

## Penalized Regression 개념

다시 회귀분석으로 돌아오면 일반 다중회귀모형에서 LSE(MSE가 최소가 되는 계수를 계산하는 방법)로 추정량 $\hat{\beta}$를 구할 수 있음. 이렇게 구한 추정량 $\hat{\beta}$은 BLUE(Best Linear Unbiased Estimator)의 성질, 즉 비편향 추정량 중에서 분산이 작은 성질이 있음.

그렇다면 왜 penalty term을 추가한 회귀분석이 필요한가?

비편향 추정량 중에서 분산이가장 작은 추정량을 구할 수 있지만 위에서 설명한 bias-variance trade off 관계를 보면 total error 관점에서는 안좋을 수 있음. 따라서 bias를 조금 포기하고 variance를 낮추는 타협점을 찾는 모형이 필요함. 기본적으로 Ridge, LASSO, Elastic net regression 등임.

Ridge, LASSO, ELASTIC NET의 특징

1.  Ridge regression

    -   제약식을 통해서 중요하지 않은 변수의 영향력을 감소시킴. 즉, 회귀계수 값을 축소함

    -   변수 간 상관관계가 높은 상황에서 예측 성능이 높음

2.  LASSO regression

    -   제약식을 통해서 중요하지 않은 변수의 영향력을 감소시킴

    -   Ridge regression과의 차이점은 중요하지 않은 변수에 해당하는 회귀계수 값을 0으로 만듦으로써 변수 선택 기능이 있음

    -   변수 간 상관관계가 높은 상황에서 변수선택 성능이 저하되므로, Ridge regression에 비해 상대적으로 예측 성능이 떨어질 수 있음

3.  Elasticnet regression

    -   변수 간 상관관계를 반영한 모형

    -   상관관계가 큰 모형을 동시에 선택 or 배제하는 특성이 있음

## Data

```{r}
data("Boston", package = "MASS")
Boston %>% head()
Boston %>% glimpse()

```

## Data split

```{r}
set.seed(123)
library(rsample)
splits <- initial_split(Boston, prop = 0.8, strata = medv)
train <- training(splits)
test <- testing(splits)


set.seed(123)
training.samples <- Boston$medv %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- Boston[training.samples, ]
test.data <- Boston[-training.samples, ]

```

## Multiple regression

```{r}
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)


lm_gridsearch <- train(medv ~ .,             
                       data = train,               
                       method = 'lm',         
                       metric = 'RMSE', 
                       trControl = control)


pred <- predict(lm_gridsearch, newdata = test)
print(RMSE(pred, test$medv))
print(R2(pred, test$medv))

```

## LASSO regression

```{r}
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)

lambda <- seq(0, 1, length = 11)  

lasso_grid <- expand.grid(alpha = 1, lambda = lambda) # alpha = 1 : lasso 

lasso_gridsearch <- train(medv ~ .,             
                       data = train,               
                       method = 'glmnet',         
                       metric = 'RMSE', 
                       trControl = control, 
                       tuneGrid = lasso_grid
                       )
lasso_gridsearch
lasso_gridsearch$bestTune
# Model coef 
coef(lasso_gridsearch$finalModel, lasso_gridsearch$bestTune$lambda)


pred <- predict(lasso_gridsearch, newdata = test)
print(RMSE(pred, test$medv))
print(R2(pred, test$medv))

```

## Ridge regression

```{r}
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)

lambda <- seq(0, 1, length = 11)

ridge_grid <- expand.grid(alpha = 0, lambda = lambda) # alpha = 0 : ridge 

ridge_gridsearch <- train(medv ~ .,             
                       data = train,               
                       method = 'glmnet',         
                       metric = 'RMSE', 
                       trControl = control, 
                       tuneGrid = ridge_grid
                       )

ridge_gridsearch
ridge_gridsearch$bestTune

# Model coef 
coef(ridge_gridsearch$finalModel, ridge_gridsearch$bestTune$lambda)


pred <- predict(ridge_gridsearch, newdata = test)
print(RMSE(pred, test$medv))
print(R2(pred, test$medv))
```

## Elastic net regression 

```{r}
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)

lambda <- 10^seq(-3, 3, length = 10) # lambda 값은 문제에서 범위를 지정해줌 
alpha <- seq(0, 1, length = 10)
elastic_grid <- expand.grid(alpha = alpha, lambda = lambda) # alpha = 0 : ridge 

elastic_gridsearch <- train(medv ~ .,             
                       data = train,               
                       method = 'glmnet',         
                       metric = 'RMSE', 
                       trControl = control, 
                       tuneGrid = elastic_grid
                       )


# Model coef 
coef(elastic_gridsearch$finalModel, elastic_gridsearch$bestTune$lambda)


pred <- predict(elastic_gridsearch, newdata = test)
print(RMSE(pred, test$medv))
print(R2(pred, test$medv))
```

# Polynomial Regression {.tabset .tabset-fade}

-   문제 : 데이터에 대한 산점도와 polynomial regression을 3차항까지 적합한 그림을 그리기

**참고: 문제에 주어진 그림만 똑같이 그리면 됨**

## Data

```{r}
set.seed(20)

x <- seq(0, 20, by = 0.1)
noise <- rnorm(length(x), mean = 10, sd = 80)
y <- 500 + 0.4*(x-10)^3 + noise

dat <- data.frame(x, y)
```

## lm fitting

```{r}
dat %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  stat_smooth(method = 'lm')
```

## Polynomial fitting(2차항)

```{r}
dat %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  stat_smooth(method = 'lm', formula = y~poly(x, 2))
```

## Polynomial fitting(3차항)

```{r}
dat %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  stat_smooth(method = 'lm', formula = y~poly(x, 3))
```

# 이원배치 분산분석 {.tabset .tabset-fade}

-   문제 : 주어진 데이터에 대해서 이원배치 분산분석을 수행하고 결과 해석

## 이원배치 분산분석 개념

-   하나의 반응변수에 대한 두 범주형 변수의 효과를 검증하는 방법
-   예를 들면 성별과 학년에 따른 시험 점수의 차이를 통계적으로 검정하기 위해 이원배치 분산분석을 실시할 수 있음
-   **범주형 변수는 반드시 factor로 구성해야함**

## Hypotheses

1.  factor A 간의 평균 차이가 없다
2.  factor B 간의 평균 차이가 없다
3.  factor A, B 간에 상호작용 효과가 없다

## Assumption

1.  정규성
2.  등분산성

**가정이 만족하는지 반드시 체크해야함**

## Data

데이터는 비타민 C가 기니피그의 치아 성장에 영향을 미치는지 통계적으로 검정하고자함

$$
\begin{align*}
&H_0 : \text{비타민 C 투여량과 기니피그의 치아 성장 사이에는 차이가 없다.} \\ 
&H_0 : \text{비타민 C 투약 방법과 기니피그의 치아 성장 사이에는 차이가 없다.} \\ 
&H_0 : \text{비타민 C 투약 방법과 비타민 C 투여량 사이에는 상호작용 효과가 존재한다.} \\ 
\end{align*}
$$

| Variable | Description                         |
|----------|-------------------------------------|
| len      | 기니피그의 치아길이                 |
| dose     | 비타민 C 투여량(mg/day)             |
| sup      | orange juice(OJ), ascorbic acid(VC) |

```{r}
data("ToothGrowth")
dat <- ToothGrowth
dat %>% glimpse()
```

## 범주형 변수 factor로 변환

```{r}
dat$dose <- factor(dat$dose, levels = c(0.5, 1, 2), labels = c("D0.5", "D1", "D2"))
dat %>% head()
```

## Visualization

```{r}
dat %>% 
  group_by(dose, supp) %>% 
  summarise(len = mean(len)) %>% 
  ungroup() -> dat_boxplot


ggplot(dat, aes(dose, len, colour=supp)) +
  geom_boxplot() +
  geom_point(data = dat_boxplot, aes(group=supp), colour="blue", 
             position = position_dodge(width=0.75)) +
  geom_line(data = dat_boxplot, aes(group=supp), 
            position = position_dodge(width=0.75)) +
  scale_x_discrete("Dose") +
  scale_y_continuous("Response")
```

## ANOVA

```{r}
aov_purr <- aov(len~supp + dose, data = dat)
summary(aov_purr)
```

## Two-way ANOVA

```{r}
# 결과 동일 
aov1 <- aov(len~supp*dose, data = dat)
aov2 <- aov(len~supp+dose + supp:dose, data = dat)

summary(aov1) 
summary(aov2)

```

**해석**

1.  supp의 p-value가 0.000231로 매우 작기 때문에 $\alpha=0.05$에서 귀무가설을 기각한다. 따라서 비타민 C 투약방법에 따른 기니피그의 치아 성장 사이에는 유의미한 차이가 존재한다.
2.  dose의 p-value가 \<2e-16로 매우 작기 때문에 $\alpha=0.05$에서 귀무가설을 기각한다. 따라서 비타민 C 투여량에 따른 기니피그의 치아 성장 사이에는 유의미한 차이가 존재한다.
3.  supp:dose의 p-value가 0.021860으로 매우 작기 때문에 $\alpha=0.05$에서 귀무가설을 기각한다. 따라서 비타민 C 투여량과 비타민 C 투약 방법 사이에는 상호작용 효과가 존재한다.

## Interaction plot

```{r}
interaction.plot(dat$dose, dat$supp, dat$len, col = c('red', 'blue'))
```

```{r}
model.tables(aov1, type = 'means', se = T)
```

## Multiple pairwise-comparisons

실제로 factor 변수 안에 어떤 그룹 간에 평균 차이가 존재하는지 알아보고자 함

```{r}
TukeyHSD(aov1, which = "dose")
```

**해석**

1.  D1(하루에 1mg의 비타민을 투여했을 때)과 D0.5(하루에 0.5mg의 비타민을 투여했을 때) 간의 평균 차이는 9.13이고, adj p-value가 0.0e+00이므로 두 그룹 간에는 평균 차이가 존재한다.
2.  D2(하루에 2mg의 비타민을 투여했을 때)과 D0.5(하루에 0.5mg의 비타민을 투여했을 때) 간의 평균 차이는 15.495이고, adj p-value가 0.0e+00이므로 두 그룹 간에는 평균 차이가 존재한다.
3.  D2(하루에 2mg의 비타민을 투여했을 때)과 D1(하루에 1mg의 비타민을 투여했을 때) 간의 평균 차이는 6.365이고, adj p-value가 2.7e-06이므로 두 그룹 간에는 평균 차이가 존재한다.

```{r}
library(DescTools)
ScheffeTest(aov1, conf.level = 0.95)
```

**scheffe's test는 turkey HSD test와 달리 모든 쌍에 대한 출력물을 산출하기 때문에 sheffe test를 이용하는 것이 효율적**

해석방법은 위에 tukey와 동일함.

## 모형 가정 확인 

1.  등분산성 가정

**그래프를 이용한 방법**

```{r}
plot(aov1, 1)
```

잔차의 값이 +-5 사이에서 고르게 분포함. 즉, 분산이 증가하거나 감소하는 경향이 없음. 따라서 등분산성 가정을 만족한다고 볼 수 있음

**검정을 이용한 방법**

```{r}
library(car)
leveneTest(len~dose, data = dat)
```

$$
\begin{align*}
&H_0 : \text{집단 간 분산이 동일하다} \\
&H_1 : \text{Not }H_0
\end{align*}
$$

$\alpha = 0.05$에서 p-value가 0.5281로 매우 크기 때문에 $H_0$를 기각할 수 없음. 따라서 등분산성 가정 만족

2.  정규성 가정

**그래프를 이용한 방법**

```{r}
plot(aov1, which = 2)
```

normal Q-Q plot에서 점들이 대부분 직선 상에 존재하기 때문에 정규성을 만족한다고 볼 수 있음

**검정을 이용한 방법**

```{r}
shapiro.test(aov1$residuals)
```

$$
\begin{align*}
&H_0 : \text{데이터가 정규분포를 따른다} \\
&H_1 : \text{Not }H_0
\end{align*}
$$

$\alpha = 0.05$에서 p-value가 0.6694로 매우 크기 때문에 $H_0$를 기각할 수 없음. 따라서 정규성 만족
