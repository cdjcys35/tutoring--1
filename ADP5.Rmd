---
title: "ADP5"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---

20회 복기

```{r}
library(tidyverse)
library(data.table)
library(lubridate)
library(caret)
library(recipes)
library(rsample)
library(forecast)
```

# 시계열 온도 예측 문제 {.tabset .tabset-fade}

## Data description

-   year: 2016년도
-   month: 월
-   day: 일
-   week: 요일
-   temp_2: 2일 이전 최대 온도
-   temp_1: 1일 이전 최대 온도
-   average: 최대 온도 평균
-   actual: 실제 최대 온도
-   friend: 친구가 예측한 값, 평균 +- 20 사이의 임의의 숫자

```{r}
temp <- fread("data/temps.csv")
temp %>% str()
```

## 데이터 전처리 (10점)

-   결측값 처리
-   필요 없는 칼럼 처리
-   전처리 완료된 결과 산출
-   데이터 무결성 증명? 
-   train/test set을 어떻게 나눌지 설명

**결측값 처리**

-   데이터 상으로 존재하지 않음
-   2016년도 1년 기준 데이터의 차원이 348, 12 이므로 시계열이 연속적이지 않음
-   따라서 시계열의 sequence가 절단되지 않도록 결측치를 채워주는 것이 바람직?

```{r}
temp %>% is.na() %>% colSums()
temp %>% dim()
```

-   2016년 day 기준 sequence를 생성하고 merge를 통해 기존 데이터를 병합해줌
-   각 변수별로 18개의 결측치가 생성됨

```{r}
temp <- temp %>% 
    mutate(date = make_date(year, month, day)) 
    

date_t <- seq(ymd("2016-01-01"), ymd("2016-12-31"), by = "1 day")

date_t %>% length()
temp %>% dim()

temp1 <- date_t %>%
    as_tibble() %>% 
    left_join(temp, by = c("value" = "date")) %>% 
    rename(date = value)

temp1 %>% is.na() %>% colSums()

```

**lag 값 비교** 
```{r}
temp1 %>% head()
temp1 %>% tail()

lag1 <- temp1$temp_1

lag1_1 <- temp1$actual %>% 
  lag(n = 1) %>% 
  replace_na(45)

lag1 == lag1_1

lag2 <- temp1$temp_2
lag2_1 <- temp1$actual %>% 
  lag(n = 2) 

lag2 == lag2_1

```

**recipes**

-   recipe를 통해 결측치 처리, 필요 없는 칼럼 처리 등 데이터 전처리를 진행해줌
-   결측치 처리 방법은 본인이 편한 걸로 선택하면 됨(문제에서 이유를 쓰라고 하지 않았기 때문에)
-   누락된 데이터에서 year, month, day, week 변수가 생성되었기 때문에 삭제하고 다시 생성해줌
-   year 변수의 경우 2016년도만 있기 때문에 제외

```{r}
rec <- temp1 %>% 
  recipe(actual~.) %>% 
  step_rm(forecast_acc, forecast_noaa, forecast_under, friend, year, month, day, week, temp_1, temp_2) %>% 
  step_meanimpute(average, actual) %>%
  step_mutate(month = month(date), 
              day = day(date), 
              week = week(date))
  
temp1 <- rec %>% prep() %>% juice()
temp1 %>% head()
temp1 %>% is.na() %>% colSums()


lag1_1 <- temp1$actual %>% 
  lag(n = 1) %>% 
  replace_na(45)

lag2_1 <- temp1$actual %>% 
  lag(n = 2)

lag2_1[1] <- 45
lag2_1[2] <- 44

lag_dat <- data.frame(temp1 = lag1_1, temp2 = lag2_1)

temp1 <- temp1 %>% 
  bind_cols(lag_dat)

```



```{r}

splits <- initial_time_split(temp1, prop = 0.7)

train <- training(splits)
test <- testing(splits)

train %>% tail()
test %>% head()

```

## Random forest로 검증 및 분석

-   Random forest의 예측한계선을 설정하는 방법을 말하고 어떤 방법을 써야 하는지 기술
-   Random forest를 활용해 예측 및 검증, 파라미터 튜닝으로 성능 강화
-   columns 별 중요도 시각화

**caret time series fold**

-   initialWindow: the initial number of consecutive values in each training set sample

-   horizon: The number of consecutive values in test set sample

-   fixedWindow: A logical: if FALSE, the training set always start at the first sample and the training set size will vary over data splits.

![](images/time.PNG)

```{r}
train %>% dim()
test %>% dim()
control <- trainControl(method='timeslice',
                        initialWindow = 110,
                        horizon = 110,
                        fixedWindow = FALSE
                        )

```

```{r}

rf_gridsearch <- train(actual ~ .,             
                       data = train,               
                       method = 'rf',  
                       trControl = control, 
                       metric = 'RMSE',
                       tuneLength = 30) 

plot(varImp(rf_gridsearch, scale = F))


pred <- predict(rf_gridsearch, newdata = test)
print(RMSE(pred, test$actual))

# 예측 한계선 
print(RMSE(test$average, test$actual))

```

## time series split 안했을 때

```{r}
splits <- initial_split(temp1, prop = 0.7)

train <- training(splits)
test <- testing(splits)

set.seed(123)
control <- trainControl(method='cv', 
                        number=5)



rf_gridsearch <- train(actual ~ .,             
                       data = train,               
                       method = 'rf',  
                       trControl = control, 
                       metric = 'RMSE',
                       tuneLength = 30) 

pred <- predict(rf_gridsearch, newdata = test)
print(RMSE(pred, test$actual))

```

## SVM로 검증 및 분석

-   SVM의 예측한계선을 설정하는 방법을 말하고 어떤 방법을 써야 하는지 기술
-   SVM를 활용해 예측 및 검증, 파라미터 튜닝으로 성능 강화
-   columns 별 중요도 시각화

```{r, warning = FALSE}
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)

svm_gridsearch <- train(actual ~ .,             
                       data = train,               
                       method = 'svmPoly',  
                       trControl = control, 
                       metric = 'RMSE',
                       tuneLength = 2) 
#plot(varImp(svm_gridsearch), scale = F)
svm_gridsearch
# DALEX	2.0.1
library(DALEX)
ex <- DALEX::explain(model = svm_gridsearch, 
               data = train[,-3], 
               y = train$actual)

vip <- model_parts(explainer = ex)
plot(vip)



pred <- predict(svm_gridsearch, newdata = test)
print(RMSE(pred, test$actual))

# 예측 한계선 
print(RMSE(test$average, test$actual))

```

## 최적 모델 선택

-   SVM과 RF의 장단점 서술
-   두 모델 중 어떤 모델이 좋은지 고르고 이유 설명
-   선택한 모델의 한계점 서술 및 해결할 방법 서술

# 군집분석 {.tabset .tabset-fade}

-   7주 동안의 전력 소비량 데이터(15분 간격으로 측정)
-   year, month, day, 가구코드, 전력사용량

```{r}
library(ResidentialEnergyConsumption)
dat <- ResidentialEnergyConsumption::elcons_15min
dat <- dat$w44[1:50, ]
date <- seq(ymd_hm('2015-01-01 00:00'),ymd_hm('2015-01-07 23:45'), by = '15 mins')

dat <- dat %>% 
    pivot_longer(col = -VID, names_to = 'date', values_to = 'power') %>% 
    select(-date)

dat <- data.frame(date = rep(date, 50)) %>% 
    bind_cols(dat) %>% 
    mutate(year = year(date), 
           month = month(date), 
           day = day(date)) %>% 
    select(VID, date, year, month, day, power)

dat %>% is.na() %>% colSums()    

```

## clustering

-   table 만들기

| 가구코드 | Date | 일사용량 total | Cluster |
|----------|------|----------------|---------|
|          |      |                |         |
|          |      |                |         |
|          |      |                |         |

```{r}
result <- dat %>% 
    group_by(VID, year, month, day) %>% 
    summarise(total = sum(power, na.rm = T)) %>% 
    ungroup()

tot <- result %>% 
    select(total)

tot <- scale(tot)

set.seed(123)
km.res <- kmeans(tot, 5, nstart = 25)

result <- result %>% 
    bind_cols(km.res$cluster) %>% 
    rename(cluster = ...6)

result

```

```{r}

dat_p <- dat %>% 
    select(power)

dat_p <- scale(dat_p)

set.seed(123)
km.res <- kmeans(dat_p, 5, nstart = 25)

dat1 <- dat %>% 
    bind_cols(km.res$cluster) %>% 
    rename(cluster = ...7)

dat1 %>% head()

```

## Heatmap으로 시각화하기

|     |      |      |      |      |          |
|-----|------|------|------|------|----------|
|     | 1:15 | 1:30 | 1:45 | 2:00 | 2:15 ... |
| 월  |      |      |      |      |          |
| 화  |      |      |      |      |          |
| 수  |      |      |      |      |          |
| 목  |      |      |      |      |          |
| 금  |      |      |      |      |          |
| 토  |      |      |      |      |          |
| 일  |      |      |      |      |          |

```{r}

dat1 %>%
    filter(cluster == 4) %>%
    mutate(wday = wday(date, label = T), 
           hour = hour(date), 
           minute = minute(date)) %>%
    mutate(hour = as.character(hour),
           minute = as.character(minute), 
           ms = paste(hour, minute, sep = ":")) %>% 
    group_by(wday, ms) %>% 
    summarise(mean_w = mean(power)) %>% 
    ungroup() %>% 
    ggplot(aes(x = ms, y = wday, fill = mean_w)) + 
    geom_tile() + 
    scale_x_discrete(guide = guide_axis(n.dodge=7))

```

# 회귀 분석 모델링 {.tabset .tabset-fade}

## train/test 7:3으로 구분

## R2/RMSE/정확도 계산

-   정확도 : 실제값\>예측값인 경우 (1-예측값/실제값), 실제값\<예측값인 경우 (1-실제값/예측값) 결과를 평균내서 산출
<<<<<<< HEAD






=======
>>>>>>> e3e99d1dbfd2c35fabeb3779d55167da7ada5b8a
