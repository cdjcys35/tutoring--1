---
title: "ADP1 실습 Regression"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")
```


# Preparations (준비작업) {.tabset .tabset-fade}

## Libraries

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}

# devtools::install_version("lubridate", version = "1.7.9.2")
library(data.table)
library(tidyverse)
library(caret)
library(recipes)
library(GGally)
library(janitor)
library(lubridate)
library(gridExtra)

theme_set(theme_bw())
```

## Data load {.tabset .tabset-fade}

```{r}
file_path <- "./data/bikesharingdata"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
dat <- fread(file.path(file_path, "train.csv"))
```

# Data overview (데이터 기본정보) {.tabset .tabset-fade}

## 변수 속성 확인

```{r}
head(dat)
glimpse(dat)
```

## 결측치 확인

```{r}
dat %>% is.na() %>% colSums()
```

# 데이터 전처리 {.tabset .tabset-fade}

## 변수 속성 변경

```{r}
dat <- dat %>% 
  mutate_at(c('weather', 'workingday', 'holiday'), factor) %>% 
  mutate(datetime = ymd_hms(datetime))

  
dat$season <- factor(dat$season, labels = c('winter', 'fall', 'summer', 'spring'))
#dat$weather <- as.factor(dat$weather)
#dat$workingday <- as.factor(dat$workingday)
#dat$holiday <- as.factor(dat$holiday)
```

## 날짜 변수 생성

```{r}
dat <- dat %>% mutate(year = year(datetime), 
                      month = month(datetime),
                      wday = wday(datetime),
                      day = day(datetime), 
                      hour = hour(datetime)) %>% 
  select(year, month, wday, day, holiday, workingday, everything()) 
```

## wday, month factor로 변환

```{r}
dat$wday <- factor(dat$wday, labels = c('Sun', 'Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat'))
dat$month <- as.factor(dat$month)
```

# 일변량 데이터 시각화 {.tabset .tabset-fade}

## count(target variable) 분포

```{r, message=FALSE, warning=FALSE}
dat %>% 
    ggplot(aes(x = count)) + 
    geom_histogram()
```

count 변수를 보면 0인 count가 많음

## atemp, temp 분포

```{r, warning=FALSE, message=FALSE}
p1 <- dat %>% 
    ggplot(aes(x = atemp)) + 
    geom_histogram()
p2 <- dat %>% 
    ggplot(aes(x = temp)) + 
    geom_histogram()
grid.arrange(grobs = list(p1, p2), col = 2)
```

temp, atemp 분포는 거의 비슷함

## casual, registered 분포

```{r}
dat %>% 
  ggplot(aes(x = registered)) + 
  geom_histogram()

dat %>% 
  ggplot(aes(x = casual)) + 
  geom_histogram()


var(dat$registered, na.rm = T)
mean(dat$registered, na.rm = T)
var(dat$casual, na.rm = T)
mean(dat$casual, na.rm = T)
```

두 변수의 분포를 보면 0의 비율이 매우 많고, 과대산포되어있는 것을 볼 수 있다.

## 변수별 상관관계 및 분포 시각화(holiday)

```{r}
dat %>% 
    select(holiday, temp, humidity, windspeed, count) %>% 
    GGally::ggpairs(mapping = aes(color = holiday))
```

## 변수별 상관관계 및 분포 시각화(workingday)

```{r}
dat %>% 
    select(workingday, temp, humidity, windspeed, count) %>% 
    GGally::ggpairs(mapping = aes(color = workingday))
```

# factor 변수 시각화 {.tabset .tabset-fade}

## 계절(season)에 따른 시간 vs count 그래프

```{r}
dat %>% 
    group_by(season, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = as.factor(season))) +
    geom_line(size = 1.5, alpha = 0.7)
```

## 날씨(weather)에 따른 시간 vs count 그래프

```{r}
dat %>% 
    group_by(weather, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = weather)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## 요일(wday)에 따른 시간 vs count 그래프

```{r}
dat %>% 
    group_by(wday, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = wday)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## 휴일 유무(holiday)에 따른 시간 vs count 그래프

```{r}
dat %>% 
    group_by(holiday, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = holiday)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## workingday에 따른 시간 vs count 그래프

```{r}
dat %>% 
    group_by(workingday, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = workingday)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## month에 따른 시간 vs count 그래프

```{r}
dat %>% 
    group_by(month, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = month)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## hour에 따른 temp vs atemp 그래프

```{r}
a1 <- dat %>% 
  mutate(hour = as.factor(hour)) %>% 
  ggplot(aes(x=hour, y = registered)) + geom_boxplot()
a2 <- dat %>% 
  mutate(hour = as.factor(hour)) %>% 
  ggplot(aes(x=hour, y = casual)) + geom_boxplot()
grid.arrange(a1, a2)
```

# 결측치 및 factor level 처리

-   weather의 경우 class 불균형
-   windspeed의 경우 0의 비율이 높음

```{r}
table(dat$weather) # class 불균형 
table(dat$windspeed==0) # 0의 비율이 높음 
```

**step_other : 범주형 변수의 level이 여러 개일 때, 하위 범주를 기타로 묶음**

-   threshhold : 전체비율에서 기타로 바꿀 비율을 조정하는 값

-   other : 기타로 바꿀 level 이름을 지정

**Example**
```{r}
# step_other
dat %>% 
    select(weather) %>% 
    table()

dat %>% 
    recipe(count~.) %>% 
    step_other(weather, threshold = 0.1, other = 3) %>% 
    prep() %>% 
    juice() %>% 
    select(weather) %>% 
    table()
```


**step_discretize : 연속형 변수를 거의 동일한 수의 데이터를 갖도록이산화하는 함수**

-   num_breaks : 데이터에서 breaks의 개수 지정

-   min_unique : unique value의 수/(cuts + 1) < min_unique 일 경우 이산화가 안됨 


**Example**
```{r}
dat %>% 
  select(windspeed) %>% 
  head()
```

```{r}
dat %>% 
  recipe(count~.) %>% 
  step_discretize(windspeed, min_unique = 3, num_breaks = 5) %>%
  prep() %>% 
  juice() %>% 
  select(windspeed) %>% 
  table()
```

**최종**
```{r}
dat <- dat %>% 
  recipe(count~.) %>% 
  step_other(weather, threshold = 0.1, other = 3) %>% 
  step_discretize(windspeed, min_unique = 3, num_breaks = 5) %>%
  prep() %>% 
  juice() 

```

# Recipe {.tabset .tabset-fade}

```{r}
dat <- dat %>% 
  recipe(count~.) %>% 
  step_rm(datetime, registered, casual) %>%
  step_mutate(year = as.factor(year)) %>%
  step_integer(month) %>% 
  step_log(count, offset = 1) %>%
  step_dummy(all_nominal()) %>%
  step_nzv(all_numeric()) %>% 
  prep() %>% 
  juice()
```

# Split train, test

```{r}
library(rsample)
splits <- initial_split(dat, prop = 0.7, strata = count)

train <- training(splits)
test <- testing(splits)
                  
```

# Modeling {.tabset .tabset-fade}

## rf

```{r}
library(caret)
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)

tunegrid <- expand.grid(mtry = c(1:5))

library(tictoc)
tic()
rf_gridsearch <- train(count ~ .,             
                       data = train,               
                       method = 'rf',  
                       trControl = control, 
                       metric = 'RMSE',
                       tuneGrid = tunegrid, 
                       verbose = F) 
toc() # 399.39 sec 
rf_gridsearch

plot(varImp(rf_gridsearch, scale = F))


pred <- predict(rf_gridsearch, newdata = test)

print(RMSE(pred, test$count))

```




## XGBOOST

```{r}
library(caret)
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)
tic()
xgb_gridsearch <- train(count ~ .,             
                       data = train,               
                       method = 'xgbTree',  
                       trControl = control, 
                       metric = 'RMSE',
                       tuneLength = 5, 
                       verbose = F) 
toc() # 344.81
plot(varImp(xgb_gridsearch, scale = F))

pred <- predict(xgb_gridsearch, newdata = test)
print(RMSE(pred, test$count))

```

## SVM

```{r}
library(caret)
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)
tic()
svm_gridsearch <- train(count ~ .,             
                       data = train,               
                       method = 'svmPoly',  
                       trControl = control, 
                       metric = 'RMSE',
                       tuneLength = 3, 
                       verbose = F) 
toc() # 738.01
pred <- predict(svm_gridsearch, newdata = test)
print(RMSE(pred, test$count))

```

## LASSO regression

```{r}
library(caret)
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)


lambda <- seq(0, 1, length = 11)  

lasso_grid <- expand.grid(alpha = 1, lambda = lambda) # alpha = 1 : lasso 

lasso_gridsearch <- train(count ~ .,             
                       data = train,               
                       method = 'glmnet',         
                       metric = 'RMSE', 
                       trControl = control, 
                       tuneGrid = lasso_grid
                       )
lasso_gridsearch
lasso_gridsearch$bestTune
# Model coef 
coef(lasso_gridsearch$finalModel, lasso_gridsearch$bestTune$lambda)


pred <- predict(lasso_gridsearch, newdata = test)
print(RMSE(pred, test$count))
```

## ridge regression

```{r}
set.seed(123)
control <- trainControl(method='cv', 
                        number=5)

lambda <- seq(0, 1, length = 11)

ridge_grid <- expand.grid(alpha = 0, lambda = lambda) # alpha = 0 : ridge 

ridge_gridsearch <- train(count ~ .,             
                       data = train,               
                       method = 'glmnet',         
                       metric = 'RMSE', 
                       trControl = control, 
                       tuneGrid = ridge_grid
                       )

ridge_gridsearch
ridge_gridsearch$bestTune

# Model coef 
coef(ridge_gridsearch$finalModel, ridge_gridsearch$bestTune$lambda)


pred <- predict(ridge_gridsearch, newdata = test)
print(RMSE(pred, test$count))

```
